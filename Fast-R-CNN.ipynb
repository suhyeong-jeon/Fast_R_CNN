{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e3d61-75c9-4d0d-8108-414e954aa1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowROIPool(nn.Module): # RoI(Region of Interest) Pooling\n",
    "    # 마지막 max pooling layer를 RoI pooling layer로 대체할때 사용함.\n",
    "    # Rol Pooling을 수행하는 feature map의 크기는 14*14*512\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(output_size)\n",
    "        self.size = output_size\n",
    "\n",
    "    # images : 14*14*512 feature map 리스트 , rois : region of interests(=region proposals) 상대좌표, roi_idx : region of interst의 index 리스트\n",
    "    def forward(self, images, rois, roi_idx):\n",
    "        n = rois.shape[0] # region of interest(region proposals)의 수\n",
    "\n",
    "        # feature map의 크기는 고정된 크기로 들어와서 h, w는 모두 14\n",
    "        h = images.size(2)\n",
    "        w = images.size(3)\n",
    "\n",
    "        # Region of Interest의 (x1, y1, x2, y2)의 행렬\n",
    "        # 상대 좌표로 들어옴\n",
    "        # rois는 원본 이미지 크기에서 region of interest가 차지하는 비율 형식으로저장되어 0~1사이의 값을 가짐\n",
    "        x1 = rois[:,0]\n",
    "        y1 = rois[:,1]\n",
    "        x2 = rois[:,2]\n",
    "        y2 = rois[:,3]\n",
    "\n",
    "        # Region of Interest의 상대좌표를 feature map에 맞게 절대 좌표로 변환\n",
    "        # 상대 좌표에 feature map의 height, weight를 곱해서 구함\n",
    "        x1 = np.floor(x1 * w).astype(int)\n",
    "        x2 = np.ceil(x2 * w).astype(int)\n",
    "        y1 = np.floor(y1 * h).astype(int)\n",
    "        y2 = np.ceil(y2 * h).astype(int)\n",
    "        \n",
    "        res = []\n",
    "        # RoI Projection\n",
    "        # region of interest의 수만큼 반복\n",
    "        for i in range(n):\n",
    "            img = images[roi_idx[i]].unsqueeze(0) # roi_idx i번째 해당하는 feature map\n",
    "            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]] # 절대 좌표의 부분을 잘라냄\n",
    "            img = self.maxpool(img) # adaptive max pooling\n",
    "            res.append(img)\n",
    "        res = torch.cat(res, dim=0)\n",
    "        return res # 7*7*(number of region proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8683150-b981-4629-9813-ebaa39c82f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained된 VGG16 모델을 load한 후 detection task에 맞게 네트워크를 수정\n",
    "class RCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        rawnet = torchvision.models.vgg16_bn(pretrained=True) # pre-trained된 vgg16_bn 모델 load (batch normalization이 추가된 VGG16 모델)\n",
    "        self.seq = nn.Sequential(*list(rawnet.features.children())[:-1]) # 마지막 max pooling 제거\n",
    "        self.roipool = SlowROIPool(output_size=(7, 7)) # 마지막 pooling layer을 RoI Pooling으로 대체\n",
    "        self.feature = nn.Sequential(*list(rawnet.classifier.children())[:-1]) # 마지막 fc layer 제거\n",
    "\n",
    "        _x = Variable(torch.Tensor(1, 3, 224, 224)) # 입력되는 데이터의 크기\n",
    "        _r = np.array([[0., 0., 1., 1.]]) \n",
    "        _ri = np.array([0])\n",
    "        _x = self.feature(self.roipool(self.seq(_x), _r, _ri).view(1, -1)) # 7*7*(number of region proposals)\n",
    "        feature_dim = _x.size(1)\n",
    "        \n",
    "        self.cls_score = nn.Linear(feature_dim, N_CLASS+1) # classifier\n",
    "        self.bbox = nn.Linear(feature_dim, 4*(N_CLASS+1)) # bounding box regressorxxxxxxxxxxxxxxxxx\n",
    "        \n",
    "        self.cel = nn.CrossEntropyLoss() # Classifier의 Loss Func\n",
    "        self.sl1 = nn.SmoothL1Loss() # Bounding Box Regressor의 Loss Func\n",
    "\n",
    "    def forward(self, inp, rois, ridx):\n",
    "        res = inp # image\n",
    "        res = self.seq(res) # 마지막 max pooling이 제거된 resnet에 image 삽입\n",
    "        res = self.roipool(res, rois, ridx) # feature map에 RoI Pooling 적용\n",
    "        res = res.detach() # 연산 X\n",
    "        res = res.view(res.size(0), -1)\n",
    "        feat = self.feature(res) # fc layers\n",
    "\n",
    "        cls_score = self.cls_score(feat) # classification result\n",
    "        bbox = self.bbox(feat).view(-1, N_CLASS+1, 4) # bounding box regressor result\n",
    "        return cls_score, bbox\n",
    "\n",
    "    # Multi-Task Loss\n",
    "    def calc_loss(self, probs, bbox, labels, gt_bbox):\n",
    "        loss_sc = self.cel(probs, labels)\n",
    "        lbl = labels.view(-1, 1, 1).expand(labels.size(0), 1, 4)\n",
    "        mask = (labels != 0).float().view(-1, 1).expand(labels.size(0), 4)\n",
    "        loss_loc = self.sl1(bbox.gather(1, lbl).squeeze(1) * mask, gt_bbox * mask)\n",
    "        lmb = 1.0\n",
    "        loss = loss_sc + lmb * loss_loc\n",
    "        return loss, loss_sc, loss_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dbb931-fb2e-4816-bf2c-5f01467ce4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch별로 Fast R-CNN 모델이 학습하는 과정 구현\n",
    "def train_batch(img, rois, ridx, gt_cls, gt_tbbox, is_val=False):\n",
    "    sc, r_bbox = rcnn(img, rois, ridx)\n",
    "    loss, loss_sc, loss_loc = rcnn.calc_loss(sc, r_bbox, gt_cls, gt_tbbox)\n",
    "    fl = loss.data.cpu().numpy()[0]\n",
    "    fl_sc = loss_sc.data.cpu().numpy()[0]\n",
    "    fl_loc = loss_loc.data.cpu().numpy()[0]\n",
    "\n",
    "    if not is_val:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return fl, fl_sc, fl_loc\n",
    "\n",
    "def train_epoch(run_set, is_val=False): # Hierarchical sampling을 통한 학습 데이터를 sampling\n",
    "    I = 2 # number of image\n",
    "    B = 64 # number of rois per image \n",
    "    POS = int(B * 0.25) # positive samples\n",
    "    NEG = B - POS # negative samples\n",
    "\n",
    "    # shuffle images\n",
    "    Nimg = len(run_set)\n",
    "    perm = np.random.permutation(Nimg)\n",
    "    perm = run_set[perm]\n",
    "    \n",
    "    losses = []\n",
    "    losses_sc = []\n",
    "    losses_loc = []\n",
    "\n",
    "    # 전체 이미지를 I개만큼 처리\n",
    "    for i in trange(0, Nimg, I):\n",
    "        lb = i\n",
    "        rb = min(i+I, Nimg)\n",
    "        torch_seg = torch.from_numpy(perm[lb:rb])\n",
    "        img = Variable(train_imgs[torch_seg], volatile=is_val).cuda()\n",
    "        ridx = []\n",
    "        glo_ids = []\n",
    "\n",
    "        for j in range(lb, rb):\n",
    "            info = train_img_info[perm[j]]\n",
    "\n",
    "            # roi의 positive, negative idx에 대한 리스트\n",
    "            pos_idx = info['pos_idx']\n",
    "            neg_idx = info['neg_idx']\n",
    "            ids = []\n",
    "\n",
    "            if len(pos_idx) > 0:\n",
    "                ids.append(np.random.choice(pos_idx, size=POS))\n",
    "            if len(neg_idx) > 0:\n",
    "                ids.append(np.random.choice(neg_idx, size=NEG))\n",
    "            if len(ids) == 0:\n",
    "                continue\n",
    "            ids = np.concatenate(ids, axis=0)\n",
    "\n",
    "            # glo_ids : 두 이미지에 대한 positive, negative sample의 idx를 저장한 리스트\n",
    "            glo_ids.append(ids)\n",
    "            ridx += [j-lb] * ids.shape[0]\n",
    "\n",
    "        if len(ridx) == 0:\n",
    "            continue\n",
    "        glo_ids = np.concatenate(glo_ids, axis=0)\n",
    "        ridx = np.array(ridx)\n",
    "\n",
    "        rois = train_roi[glo_ids]\n",
    "        gt_cls = Variable(torch.from_numpy(train_cls[glo_ids]), volatile=is_val).cuda()\n",
    "        gt_tbbox = Variable(torch.from_numpy(train_tbbox[glo_ids]), volatile=is_val).cuda()\n",
    "\n",
    "        loss, loss_sc, loss_loc = train_batch(img, rois, ridx, gt_cls, gt_tbbox, is_val=is_val)\n",
    "        losses.append(loss)\n",
    "        losses_sc.append(loss_sc)\n",
    "        losses_loc.append(loss_loc)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    avg_loss_sc = np.mean(losses_sc)\n",
    "    avg_loss_loc = np.mean(losses_loc)\n",
    "    print(f'Avg loss = {avg_loss:.4f}; loss_sc = {avg_loss_sc:.4f}, loss_loc = {avg_loss_loc:.4f}')\n",
    "    \n",
    "    return losses, losses_sc, losses_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d85b3-7279-469b-8c52-a1ee88074cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_to_bbox(img_size, reg, box):\n",
    "    img_width, img_height = img_size\n",
    "    bbox_width = box[:,2] - box[:,0] + 1.0\n",
    "    bbox_height = box[:,3] - box[:,1] + 1.0\n",
    "    bbox_ctr_x = box[:,0] + 0.5 * bbox_width\n",
    "    bbox_ctr_y = box[:,1] + 0.5 * bbox_height\n",
    "\n",
    "    bbox_width = bbox_width[:,np.newaxis]\n",
    "    bbox_height = bbox_height[:,np.newaxis]\n",
    "    bbox_ctr_x = bbox_ctr_x[:,np.newaxis]\n",
    "    bbox_ctr_y = bbox_ctr_y[:,np.newaxis]\n",
    "\n",
    "    out_ctr_x = reg[:,:,0] * bbox_width + bbox_ctr_x\n",
    "    out_ctr_y = reg[:,:,1] * bbox_height + bbox_ctr_y\n",
    "\n",
    "    out_width = bbox_width * np.exp(reg[:,:,2])\n",
    "    out_height = bbox_height * np.exp(reg[:,:,3])\n",
    "\n",
    "    return np.array([\n",
    "        np.maximum(0, out_ctr_x - 0.5 * out_width),\n",
    "        np.maximum(0, out_ctr_y - 0.5 * out_height),\n",
    "        np.minimum(img_width, out_ctr_x + 0.5 * out_width),\n",
    "        np.minimum(img_height, out_ctr_y + 0.5 * out_height)\n",
    "    ]).transpose([1, 2, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
